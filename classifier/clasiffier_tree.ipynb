{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>APRENDIZAJE SUPERVISADO</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cada linea estara explicita, en forma de comentario \"#\", la función de esa fracción de codigo para el desarrollo de la actividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Antes de iniciar instalar\n",
    "#pip3 install pydotplus\n",
    "#pip3 install sklearn\n",
    "#pip3 install pandas\n",
    "#pip3 install numpy\n",
    "#pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zirei/.local/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Se importa todo el set de sklearn que utilizaremos( pandas, sklearn, numpy, joblib), \n",
    "#para la parte gráfica tenemos (IPython, pydotplus), usamos os para tener acceso a archivos del sistema.\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz  # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals.six import StringIO  \n",
    "import numpy as np\n",
    "from IPython.display import Image  \n",
    "import os\n",
    "from joblib import dump, load \n",
    "import pydotplus\n",
    "from io import StringIO\n",
    "import random as rd\n",
    "#For cross validation techniques\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Es un método que crea datos de forma aleatoria para predecir el klout usando los modelos que se crearán más adelante.\n",
    "def prediction_example(clf):\n",
    "    # Each parameter has a range based on \"datosLimpios.csv\" training file\n",
    "    # Ranges for simulation may vary if a new Training file is created\n",
    "    Hour = rd.randrange(0,24)\n",
    "    Day = rd.randrange(1,32)\n",
    "    Reach_procentaje = rd.randrange(0,101)\n",
    "    IsReshare = rd.randrange(0,2)\n",
    "    RetweetCount = rd.randrange(0,26128)\n",
    "    # Make new observation\n",
    "    observation = [[Hour, Day, Reach_procentaje, IsReshare, RetweetCount]] \n",
    "    # Generate random values\n",
    "    print(\"The generated values are: \", observation)\n",
    "    # Predict observation's class (STARTING FROM 0 to 100%)    \n",
    "    prediction = clf.predict(observation)\n",
    "    print(\"class Klout predicted is:\", prediction[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Es un método que crea datos de forma aleatoria para predecir los likes que tendra una publicación en base a\n",
    "#los modelos que se crearán más adelante.\n",
    "def prediction_example2(clf):\n",
    "    # Each parameter has a range based on \"datosLimpios.csv\" training file\n",
    "    # Ranges for simulation may vary if a new Training file is created\n",
    "    Hour = rd.randrange(0,24)\n",
    "    Day = rd.randrange(1,32)\n",
    "    IsReshare = rd.randrange(0,2)\n",
    "    Reach = rd.randrange(0, 10342453)\n",
    "    RetweetCount = rd.randrange(0,26128)\n",
    "    # Make new observation\n",
    "    observation = [[Hour, Day, IsReshare, Reach, RetweetCount]] \n",
    "    # Generate random values\n",
    "    print(\"The generated values are: \", observation)\n",
    "    # Predict observation's class (STARTING FROM 0 to 100%)    \n",
    "    prediction = clf.predict(observation)\n",
    "    print(\"You've got:\", prediction[0], \"Likes\",\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El entrenamiento del modelo klout\n",
    "def train_model():\n",
    "    classifier_filename = 'classifier_model.joblib'\n",
    "    feature_cols = ['Hour', 'Day', 'Reach_procentaje', 'IsReshare', 'RetweetCount']\n",
    "\n",
    "    # Check if model file (.joblib extension) exist and use it as the classifier model\n",
    "    model_exist = os.path.isfile(classifier_filename)\n",
    "\n",
    "    if model_exist == False:  # Proceed to training\n",
    "        col_names = ['Hour', 'Day', 'Reach_procentaje', 'IsReshare', 'RetweetCount', 'Klout']\n",
    "        \n",
    "        training = pd.read_csv(\"../datasets/datosLimpios.csv\", header=0, names=col_names)  # load dataset\n",
    "        \n",
    "        # Split dataset in features and target variable\n",
    "        x = training[feature_cols] # Features\n",
    "        y = training.Klout # Target variable\n",
    "        \n",
    "        # Split dataset into training set and test set (70% training and 20% test)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "       \n",
    "        \n",
    "        clf = DecisionTreeClassifier() # Create Decision Tree classifer object\n",
    "        clf = clf.fit(x_train,y_train) # Train Decision Tree Classifer\n",
    "        \n",
    "        #Accurracy\n",
    "        y_pred = clf.predict(x_test)\n",
    "        #Validatión\n",
    "        score = clf.score(x_train,y_train)\n",
    "        preds = clf.predict(x_test)\n",
    "    \n",
    "        #Metrics\n",
    "        calc_accuracy(clf, y_test, y_pred)\n",
    "        validation(clf, score, preds, y_test, x_train, y_train)\n",
    "                   \n",
    "        # Graph tree data (the output is a \"tree.png\" image)\n",
    "        #graph_data(clf, feature_cols)\n",
    "\n",
    "        dump(clf, classifier_filename)  # Write model in a file (persistance)\n",
    "    else:\n",
    "        clf = load(classifier_filename)  # Load classification model from file \n",
    "        print(\"Running Klout classifier\")\n",
    "        \n",
    "        # Call prediction_example function (classifying events instead of simulating them with the method\n",
    "        # \"output_events_randomly\")\n",
    "        for _ in range(10):\n",
    "           prediction_example(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El entrenamiento del modelo de Likes\n",
    "def train_model2():\n",
    "    classifier_filename = 'classifier_model2.joblib'\n",
    "    feature_cols = ['Hour', 'Day', 'IsReshare', 'Reach', 'RetweetCount']\n",
    "\n",
    "    # Check if model file (.joblib extension) exist and use it as the classifier model\n",
    "    model_exist = os.path.isfile(classifier_filename)\n",
    "\n",
    "    if model_exist == False:  # Proceed to training\n",
    "        col_names = ['Hour', 'Day', 'IsReshare', 'Reach', 'RetweetCount', 'Likes']\n",
    "        \n",
    "        training = pd.read_csv(\"../datasets/datosLimpios2.csv\", header=0, names=col_names)  # load dataset\n",
    "        \n",
    "        # Split dataset in features and target variable\n",
    "        x = training[feature_cols] # Features\n",
    "        y = training.Likes # Target variable\n",
    "        \n",
    "        # Split dataset into training set and test set (70% training and 20% test)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "       \n",
    "        \n",
    "        clf = DecisionTreeClassifier() # Create Decision Tree classifer object\n",
    "        clf = clf.fit(x_train,y_train) # Train Decision Tree Classifer\n",
    "        \n",
    "        #Accurracy\n",
    "        y_pred = clf.predict(x_test)\n",
    "        #Validatión\n",
    "        score = clf.score(x_train,y_train)\n",
    "        preds = clf.predict(x_test)\n",
    "    \n",
    "        #Metrics\n",
    "        calc_accuracy(clf, y_test, y_pred)\n",
    "        validation(clf, score, preds, y_test, x_train, y_train)\n",
    "                   \n",
    "        # Graph tree data (the output is a \"tree.png\" image)\n",
    "        #graph_data(clf, feature_cols)\n",
    "\n",
    "        dump(clf, classifier_filename)  # Write model in a file (persistance)\n",
    "    else:\n",
    "        clf = load(classifier_filename)  # Load classification model from file \n",
    "        print(\"Running Likes classifier\")\n",
    "        \n",
    "        # Call prediction_example function (classifying events instead of simulating them with the method\n",
    "        # \"output_events_randomly\")\n",
    "        for _ in range(10):\n",
    "           prediction_example2(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validación cruzada\n",
    "def validation(clf, score, preds, y_test, x_train, y_train):\n",
    "    # Calculate Accuracy. How often is the classifier correct?\n",
    "        #Starting model validation metrics\n",
    "                \n",
    "        # To apply validation techniques\n",
    "        kf = KFold(n_splits=5)\n",
    "        \n",
    "        print(\"Metrica del modelo\", score)\n",
    "\n",
    "        scores = cross_val_score(clf, x_train, y_train, cv=kf, scoring=\"accuracy\")\n",
    "\n",
    "        print(\"Metricas cross_validation\", scores)\n",
    "\n",
    "        print(\"Media de cross_validation\", scores.mean())\n",
    "\n",
    "        score_pred = metrics.accuracy_score(y_test, preds)\n",
    "\n",
    "        print(\"Metrica en Test\", score_pred)\n",
    "        # End of model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metricas de calidad, average weighted es para tomar el valor ponderado.\n",
    "def calc_accuracy(clf, y_test, y_pred):\n",
    "    # Calculate Accuracy. How often is the classifier correct?\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    #print(\"Precision: \", metrics.precision_score(y_test, y_pred, average='weighted'))\n",
    "    #print(\"Sensibilidad: \", metrics.recall_score(y_test, y_pred, average='weighted'))\n",
    "    #print(\"Puntaje F1: \", metrics.f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def graph_data(clf, feature_cols):\n",
    "    #Creates an image (tree.png) that represents the shape of the classifier_tree\n",
    "    #This is for illustrative purposes only (it uses a shorter training file than the current training file)\n",
    "    #dot_data = StringIO()\n",
    "    #export_graphviz(clf, out_file=dot_data,  \n",
    "                    #filled=True, rounded=True,\n",
    "                    #Name of the leaves of the tree\n",
    "                    #special_characters=True, feature_names = feature_cols, class_names=['0','1','2','3','4','5'])\n",
    "    #(graph, )= pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    #graph.write_png('tree.png')\n",
    "    #Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.105\n",
      "Metrica del modelo 0.481625\n",
      "Metricas cross_validation [0.1074375 0.103125  0.1084375 0.1050625 0.1043125]\n",
      "Media de cross_validation 0.105675\n",
      "Metrica en Test 0.105\n"
     ]
    }
   ],
   "source": [
    "#Klou statistics\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99335\n",
      "Metrica del modelo 1.0\n"
     ]
    }
   ],
   "source": [
    "#Likes statistics\n",
    "train_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplos simulados\n",
    "train_model()\n",
    "train_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
